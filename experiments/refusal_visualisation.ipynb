{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdkByxVYqRpz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harmless_act = torch.load('harmless_activations.pt')\n",
        "harmful_act = torch.load('harmful_activations.pt')\n",
        "intervention_act = torch.load('intervention_activations.pt')\n",
        "\n",
        "layers_to_analyze = [4, 8, 12, 16, 20]\n",
        "refusal_rate = \"86%\""
      ],
      "metadata": {
        "id": "gLZnsdfXqSjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imported_activation_pca(harmless_act, harmful_act, intervention_act, layers, refusal_rate):\n",
        "    fig, axs = plt.subplots(len(layers) // 2, 2, figsize=(20, 16))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for idx, layer in enumerate(layers):\n",
        "        # combine activations & apply PCA\n",
        "        all_activations = torch.cat([harmless_act, harmful_act, intervention_act], dim=0)\n",
        "        pca = PCA(n_components=2)\n",
        "        projected_activations = pca.fit_transform(all_activations.cpu().numpy())\n",
        "\n",
        "        n = len(harmful_act)\n",
        "        harmless_proj = projected_activations[:n]\n",
        "        harmful_proj = projected_activations[n:2*n]\n",
        "        intervention_proj = projected_activations[2*n:]\n",
        "\n",
        "        # plot on the corresponding subplot\n",
        "        axs[idx].scatter(harmless_proj[:, 0], harmless_proj[:, 1], color='green', label='Harmless', alpha=0.6)\n",
        "        axs[idx].scatter(harmful_proj[:, 0], harmful_proj[:, 1], color='red', label='Harmful', alpha=0.6)\n",
        "        axs[idx].scatter(intervention_proj[:, 0], intervention_proj[:, 1], color='blue', label='Intervention', alpha=0.6)\n",
        "\n",
        "        axs[idx].legend()\n",
        "        axs[idx].set_title(f\"PCA of Activations at Layer {layer}\")\n",
        "        axs[idx].set_xlabel(\"PC 1\")\n",
        "        axs[idx].set_ylabel(\"PC 2\")\n",
        "\n",
        "    fig.suptitle(f\"Refusal Direction PCA\\nBase model + LAT adapter\\nRefusal Rate: {refusal_rate:.2%}\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"refusal_direction_pca_multi_layer.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "9Yqg1s_vqy7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers_to_analyze = [1, 2, 3, 4, 8, 12, 16, 20]\n",
        "\n",
        "imported_activation_pca(\n",
        "    harmless_act,\n",
        "    harmful_act,\n",
        "    intervention_act,\n",
        "    layers_to_analyze,\n",
        "    refusal_rate\n",
        "  )"
      ],
      "metadata": {
        "id": "SjDRrSZDrg3N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}